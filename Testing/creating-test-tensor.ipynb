{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\nimport numpy as np\nfrom spectral import open_image\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-31T18:02:04.287256Z","iopub.execute_input":"2022-05-31T18:02:04.287906Z","iopub.status.idle":"2022-05-31T18:02:06.136099Z","shell.execute_reply.started":"2022-05-31T18:02:04.287797Z","shell.execute_reply":"2022-05-31T18:02:06.135312Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.137653Z","iopub.execute_input":"2022-05-31T18:02:06.138190Z","iopub.status.idle":"2022-05-31T18:02:06.203675Z","shell.execute_reply.started":"2022-05-31T18:02:06.138152Z","shell.execute_reply":"2022-05-31T18:02:06.202886Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\nimport numpy as np\nfrom spectral import open_image\nimport pickle\nimport cv2\nimport rasterio","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.204959Z","iopub.execute_input":"2022-05-31T18:02:06.205932Z","iopub.status.idle":"2022-05-31T18:02:06.743665Z","shell.execute_reply.started":"2022-05-31T18:02:06.205895Z","shell.execute_reply":"2022-05-31T18:02:06.742934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class numpyDataset:\n    \"\"\"returns bigger image you need to split them while training.\"\"\"\n\n    def __init__(self, file_paths, std_scaler_path=None,normalization_par = None):\n        \"\"\"\n        Args:\n            file_paths (list): list of filepaths of HDR files .\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.file_IDs = file_paths # HDR file path\n        self.normalization_par = normalization_par\n        if normalization_par == None:\n            dbfile = open(std_scaler_path, 'rb')\n            self.standardisation_param = pickle.load(dbfile)\n\n    def __len__(self):\n        return len(self.file_IDs)\n\n    def getitem(self, index: int):\n        filepath = self.file_IDs[index]\n        image_sample = rasterio.open(str(filepath), \"r\")\n        bands = [i for i in range(1, image_sample.count+1)]\n        image_sample = image_sample.read(bands)\n        image_sample = image_sample.astype('float32')\n        \n        img_std = image_sample/5500\n        \n        #img_std = np.expand_dims(img_std, axis=0)\n\n        img_tensor = torch.from_numpy(img_std)\n        \n\n        sample = (img_tensor, 0)\n\n        return sample","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.746285Z","iopub.execute_input":"2022-05-31T18:02:06.747129Z","iopub.status.idle":"2022-05-31T18:02:06.755861Z","shell.execute_reply.started":"2022-05-31T18:02:06.747091Z","shell.execute_reply":"2022-05-31T18:02:06.755093Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"list_of_best_images = [\n    '../input/eurosat-dataset/EuroSATallBands/AnnualCrop/AnnualCrop_1026.tif',\n    '../input/eurosat-dataset/EuroSATallBands/HerbaceousVegetation/HerbaceousVegetation_1032.tif',\n    '../input/eurosat-dataset/EuroSATallBands/Highway/Highway_1012.tif',\n    '../input/eurosat-dataset/EuroSATallBands/Industrial/Industrial_10.tif',\n    '../input/eurosat-dataset/EuroSATallBands/Pasture/Pasture_1044.tif',\n    '../input/eurosat-dataset/EuroSATallBands/PermanentCrop/PermanentCrop_1013.tif',\n    '../input/eurosat-dataset/EuroSATallBands/River/River_1004.tif',\n    '../input/eurosat-dataset/EuroSATallBands/SeaLake/SeaLake_1002.tif',\n    '../input/eurosat-dataset/EuroSATallBands/AnnualCrop/AnnualCrop_1064.tif',\n    '../input/eurosat-dataset/EuroSATallBands/HerbaceousVegetation/HerbaceousVegetation_100.tif',\n    '../input/eurosat-dataset/EuroSATallBands/Highway/Highway_1034.tif',\n    '../input/eurosat-dataset/EuroSATallBands/Industrial/Industrial_1017.tif',\n    '../input/eurosat-dataset/EuroSATallBands/Pasture/Pasture_1068.tif',\n    '../input/eurosat-dataset/EuroSATallBands/PermanentCrop/PermanentCrop_1073.tif',\n    '../input/eurosat-dataset/EuroSATallBands/River/River_103.tif',\n    '../input/eurosat-dataset/EuroSATallBands/SeaLake/SeaLake_1072.tif'\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.758738Z","iopub.execute_input":"2022-05-31T18:02:06.759040Z","iopub.status.idle":"2022-05-31T18:02:06.766433Z","shell.execute_reply.started":"2022-05-31T18:02:06.759014Z","shell.execute_reply":"2022-05-31T18:02:06.765711Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(list_of_best_images)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.768575Z","iopub.execute_input":"2022-05-31T18:02:06.769514Z","iopub.status.idle":"2022-05-31T18:02:06.780221Z","shell.execute_reply.started":"2022-05-31T18:02:06.769487Z","shell.execute_reply":"2022-05-31T18:02:06.779464Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"DL = numpyDataset(list_of_best_images, normalization_par = 5500)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.781661Z","iopub.execute_input":"2022-05-31T18:02:06.782226Z","iopub.status.idle":"2022-05-31T18:02:06.787881Z","shell.execute_reply.started":"2022-05-31T18:02:06.782190Z","shell.execute_reply":"2022-05-31T18:02:06.787198Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"DL.__len__()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.788802Z","iopub.execute_input":"2022-05-31T18:02:06.789728Z","iopub.status.idle":"2022-05-31T18:02:06.798419Z","shell.execute_reply.started":"2022-05-31T18:02:06.789699Z","shell.execute_reply":"2022-05-31T18:02:06.797711Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_tensor_vis = []\nfor i in range(16):\n    test_tensor_vis.append(DL.getitem(i)[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:06.799639Z","iopub.execute_input":"2022-05-31T18:02:06.800422Z","iopub.status.idle":"2022-05-31T18:02:08.027594Z","shell.execute_reply.started":"2022-05-31T18:02:06.800373Z","shell.execute_reply":"2022-05-31T18:02:08.026852Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_tensor_vis = torch.stack(test_tensor_vis).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:31.167855Z","iopub.execute_input":"2022-05-31T18:02:31.168289Z","iopub.status.idle":"2022-05-31T18:02:33.993321Z","shell.execute_reply.started":"2022-05-31T18:02:31.168253Z","shell.execute_reply":"2022-05-31T18:02:33.992494Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"torch.save(test_tensor_vis, 'test_tensor_vis.pt')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:03:05.267502Z","iopub.execute_input":"2022-05-31T18:03:05.267870Z","iopub.status.idle":"2022-05-31T18:03:05.284603Z","shell.execute_reply.started":"2022-05-31T18:03:05.267835Z","shell.execute_reply":"2022-05-31T18:03:05.283873Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_tensor_vis.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:03:47.288310Z","iopub.execute_input":"2022-05-31T18:03:47.288865Z","iopub.status.idle":"2022-05-31T18:03:47.294917Z","shell.execute_reply.started":"2022-05-31T18:03:47.288801Z","shell.execute_reply":"2022-05-31T18:03:47.294021Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('../input/eurosat-dataset/EuroSATallBands/SeaLake')[-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T17:48:42.679299Z","iopub.execute_input":"2022-05-31T17:48:42.679703Z","iopub.status.idle":"2022-05-31T17:48:42.840792Z","shell.execute_reply.started":"2022-05-31T17:48:42.679673Z","shell.execute_reply":"2022-05-31T17:48:42.839824Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_tensor_vis","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:02:08.138311Z","iopub.status.idle":"2022-05-31T18:02:08.138627Z","shell.execute_reply.started":"2022-05-31T18:02:08.138477Z","shell.execute_reply":"2022-05-31T18:02:08.138492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport os\nimport torch\n\nclass logger_regression:\n    def __init__(self,test_tensor_path,device):\n        self.losslistinstance_train = []\n        self.losslistinstance_train_cont = []\n        self.epochwiselosstrain = []\n\n        self.losslistinstance_val = []\n        self.losslistinstance_val_cont = []\n        self.epochwiselossval = []\n\n        self.mselistinstance_val = []\n        self.epochwisemseval = []\n\n        self.psnrlistinstance_val = []\n        self.epochwisepsnrval = []\n\n        self.test_tensor = torch.load(test_tensor_path)\n        self.device = device\n\n        self.LRS = []\n        self.imagenumber = 0\n        if os.path.exists('visuals'):\n            pass\n        else:\n            os.mkdir('visuals')\n\n    def updateLossListTrain(self,loss,LRC):\n        self.losslistinstance_train.append(loss)\n        self.LRS.append(LRC)\n\n    def updateLossListval(self,lossdict):\n        loss = lossdict['loss']\n        mse = lossdict['mse']\n        psnr = lossdict['psnr']\n        self.losslistinstance_val.append(loss)\n        self.mselistinstance_val.append(mse)\n        self.psnrlistinstance_val.append(psnr)\n\n    def displayLossTrain(self):\n        avg_loss = np.array(self.losslistinstance_train).mean()\n        print(\"Train: Average Squared Recunstruction Loss:\",avg_loss)\n\n    def displayLossval(self):\n        avg_loss = np.array(self.losslistinstance_val).mean()\n        avg_MSE = np.array(self.mselistinstance_val).mean()\n        avg_PSNR = np.array(self.psnrlistinstance_val).mean()\n        print(\"Val: Average Squared Recunstruction Loss:\",avg_loss)\n        print(\"Val: Average MSE between original images and Recunstructed images:\",avg_MSE)\n        print(\"Val: Average PSNR between original images and Recunstructed images:\", avg_PSNR)\n        return avg_loss\n\n    def resetTrainLoss(self):\n        avg_loss = np.array(self.losslistinstance_train).mean()\n        self.epochwiselosstrain.append(avg_loss)\n        self.losslistinstance_train_cont.extend(self.losslistinstance_train)\n        self.losslistinstance_train = []\n\n    def resetvalLoss(self):\n        avg_loss = np.array(self.losslistinstance_val).mean()\n        avg_MSE = np.array(self.mselistinstance_val).mean()\n        avg_PSNR = np.array(self.psnrlistinstance_val).mean()\n\n        self.epochwiselossval.append(avg_loss)\n        self.epochwisemseval.append(avg_MSE)\n        self.epochwisepsnrval.append(avg_PSNR)\n\n        self.losslistinstance_val_cont.extend(self.losslistinstance_val)\n\n        self.losslistinstance_val = []\n        self.mselistinstance_val = []\n        self.psnrlistinstance_val = []\n\n\n    def plotLoss(self):\n        plt.plot(self.epochwiselosstrain, '-bx')\n        plt.plot(self.epochwiselossval, '-rx')\n        plt.xlabel('epochs')\n        plt.ylabel('loss')\n        plt.legend(['Training', 'Validation'])\n        plt.title('Loss vs. No. of epochs')\n        plt.savefig('visuals/0_lossplot.png')\n        plt.show()\n\n        plt.plot(self.epochwisemseval, '-bx')\n        plt.xlabel('epochs')\n        plt.ylabel('MSE')\n        plt.title('Val: MSE vs. No. of Epochs')\n        plt.savefig('visuals/0_mse.png')\n        plt.show()\n\n        plt.plot(self.epochwisepsnrval, '-bx')\n        plt.xlabel('epochs')\n        plt.ylabel('PSNR (in dB)')\n        plt.title('Val: PSNR vs. No. of Epochs')\n        plt.savefig('visuals/0_psnr.png')\n        plt.show()\n\n        plt.plot(self.losslistinstance_train_cont, '-bx')\n        plt.xlabel('Training Steps')\n        plt.ylabel('Loss')\n        plt.title('Train: Loss vs. No. of Steps')\n        plt.savefig('visuals/0_train_cont_loss.png')\n        plt.show()\n\n        plt.plot(self.losslistinstance_val_cont, '-bx')\n        plt.xlabel('Validation Steps')\n        plt.ylabel('Loss')\n        plt.title('Val: Loss vs. No. of Steps')\n        plt.savefig('visuals/0_val_cont_loss.png')\n        plt.show()\n\n    def plotLR(self):\n        plt.plot(self.LRS)\n        plt.xlabel('Batch no.')\n        plt.ylabel('Learning rate')\n        plt.title('Learning Rate vs. Batch no.')\n        plt.savefig('visuals/0_LRplot.png')\n        plt.show()\n\n    def visualize_io(self,model):\n        o = model(self.test_tensor.to(self.device))\n\n        im_arr_ip = []\n        for i in range(8):\n            im_arr_ip.append(self.test_tensor.cpu().numpy()[i,2, :, :])\n\n        for i in range(8):\n            im_arr_ip.append(o.cpu().detach().numpy()[i,2, :, :])\n\n        fig = plt.figure(figsize=(20., 5.))\n\n        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                         nrows_ncols=(2, 8),  # creates 2x2 grid of axes\n                         axes_pad=0.1,  # pad between axes in inch.\n                         )\n\n        for ax, im in zip(grid, im_arr_ip):\n            # Iterating over the grid returns the Axes.\n            ax.imshow(im, cmap='gray')\n\n        plt.savefig('visuals/io_' + str(self.imagenumber) + '.png')\n        self.imagenumber = self.imagenumber + 1\n        plt.show()\n\n    def savemodel(self,model,modelpath):\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:11:55.045934Z","iopub.execute_input":"2022-05-31T18:11:55.046313Z","iopub.status.idle":"2022-05-31T18:11:55.072486Z","shell.execute_reply.started":"2022-05-31T18:11:55.046279Z","shell.execute_reply":"2022-05-31T18:11:55.071725Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n#Encoder V3 Dataset V2\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.sigmoid = nn.Sigmoid()\n        self.leakyreLU = nn.LeakyReLU()\n        \n        #encoder\n        \n        self.conv1_1 = nn.Conv2d(in_channels=13, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv1_2= nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1, stride=2, padding=0)\n        self.batch_norm1 = nn.BatchNorm2d(32)\n        \n        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv2_2= nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1, stride=2, padding=0)\n        self.batch_norm2 = nn.BatchNorm2d(32)\n        \n        self.conv3_1 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv3_2= nn.Conv2d(in_channels=16, out_channels=16, kernel_size=1, stride=2, padding=0)\n        self.batch_norm3 = nn.BatchNorm2d(16)\n        \n        self.conv4_1 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n        self.conv4_2= nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1, stride=2, padding=0)\n        self.batch_norm4 = nn.BatchNorm2d(8)\n        \n        \n        # Decoder\n        \n        self.convT1_1 = nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=1, stride=2,output_padding=1)\n        self.convT1_2=nn.ConvTranspose2d(in_channels=8, out_channels=16, kernel_size=3, stride=1,output_padding=0,padding=1)\n        self.batch_norm5 = nn.BatchNorm2d(16)\n        \n        self.convT2_1 = nn.ConvTranspose2d(in_channels=16, out_channels=16, kernel_size=1, stride=2,output_padding=1)\n        self.convT2_2=nn.ConvTranspose2d(in_channels=16, out_channels=32, kernel_size=3, stride=1,output_padding=0,padding=1)\n        self.batch_norm6 = nn.BatchNorm2d(32)\n        \n        self.convT3_1 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=1, stride=2,output_padding=1)\n        self.convT3_2= nn.ConvTranspose2d(in_channels=32, out_channels=64, kernel_size=3, stride=1,output_padding=0,padding=1)\n        self.batch_norm7 = nn.BatchNorm2d(64)\n        \n        self.convT4_1 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=1, stride=2,output_padding=1)\n        self.convT4_2= nn.ConvTranspose2d(in_channels=32, out_channels=13, kernel_size=3, stride=1,output_padding=0,padding=1)\n\n\n    def forward(self, x):\n        x = self.leakyreLU(self.batch_norm1(self.conv1_2(self.conv1_1(x))))\n        #x = self.leakyreLU(self.batch_norm2(self.conv2_2(self.conv2_1(x))))\n        #x = self.leakyreLU(self.batch_norm3(self.conv3_2(self.conv3_1(x))))\n        #x = self.leakyreLU(self.batch_norm4(self.conv4_2(self.conv4_1(x))))\n\n        #x = self.leakyreLU(self.batch_norm5(self.convT1_2(self.convT1_1(x))))\n        #x = self.leakyreLU(self.batch_norm6(self.convT2_2(self.convT2_1(x))))\n        #x = self.leakyreLU(self.batch_norm7(self.convT3_2(self.convT3_1(x))))\n        x = self.sigmoid(self.convT4_2(self.convT4_1(x)))\n        return x\n\n\nmodel = Net()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:07:40.503764Z","iopub.execute_input":"2022-05-31T18:07:40.504232Z","iopub.status.idle":"2022-05-31T18:07:40.529548Z","shell.execute_reply.started":"2022-05-31T18:07:40.504195Z","shell.execute_reply":"2022-05-31T18:07:40.528803Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:08:05.617461Z","iopub.execute_input":"2022-05-31T18:08:05.617810Z","iopub.status.idle":"2022-05-31T18:08:05.626526Z","shell.execute_reply.started":"2022-05-31T18:08:05.617778Z","shell.execute_reply":"2022-05-31T18:08:05.625733Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"logger = logger_regression('test_tensor_vis.pt', device)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:12:11.758053Z","iopub.execute_input":"2022-05-31T18:12:11.758718Z","iopub.status.idle":"2022-05-31T18:12:11.768551Z","shell.execute_reply.started":"2022-05-31T18:12:11.758680Z","shell.execute_reply":"2022-05-31T18:12:11.767732Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"logger.visualize_io(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T18:12:24.033013Z","iopub.execute_input":"2022-05-31T18:12:24.033854Z","iopub.status.idle":"2022-05-31T18:12:26.457409Z","shell.execute_reply.started":"2022-05-31T18:12:24.033787Z","shell.execute_reply":"2022-05-31T18:12:26.456645Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}